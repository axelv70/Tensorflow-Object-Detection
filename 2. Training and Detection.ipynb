{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "# CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet_tuned'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/install/source_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "id": "K-Cmz2edpfDE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iA1DIq5OpfDE"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}\n",
    "# cloning tensorflow object detection api from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJjMHbnDs3Tv"
   },
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Installing other dependencies required for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.13.0\n",
      "  Using cached tensorflow-2.13.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0\n",
      "  Using cached tensorflow_intel-2.13.0-cp310-cp310-win_amd64.whl (276.5 MB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (1.6.3)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\absl_py-2.1.0-py3.10.egg (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (2.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (1.60.1)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (4.5.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\h5py-3.10.0-py3.10-win-amd64.egg (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (3.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (23.5.26)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\tensorflow_io_gcs_filesystem-0.31.0-py3.10-win-amd64.egg (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (0.31.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (16.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (1.16.0)\n",
      "Requirement already satisfied: packaging in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (4.23.4)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (1.24.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (0.4.0)\n",
      "Requirement already satisfied: setuptools in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow==2.13.0) (65.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow==2.13.0) (0.42.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (3.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (2.27.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (3.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (2.31.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0) (3.2.2)\n",
      "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.1\n",
      "    Uninstalling tensorboard-2.15.1:\n",
      "      Successfully uninstalled tensorboard-2.15.1\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.15.0\n",
      "    Uninstalling tensorflow-intel-2.15.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.15.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0\n",
      "    Uninstalling tensorflow-2.15.0:\n",
      "      Successfully uninstalled tensorflow-2.15.0\n",
      "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-models-official 2.15.0 requires google-api-python-client>=1.6.7, which is not installed.\n",
      "tf-models-official 2.15.0 requires immutabledict, which is not installed.\n",
      "tf-models-official 2.15.0 requires kaggle>=1.3.9, which is not installed.\n",
      "tf-models-official 2.15.0 requires oauth2client, which is not installed.\n",
      "tf-models-official 2.15.0 requires opencv-python-headless, which is not installed.\n",
      "tf-models-official 2.15.0 requires py-cpuinfo>=3.3.0, which is not installed.\n",
      "tf-models-official 2.15.0 requires sentencepiece, which is not installed.\n",
      "tf-models-official 2.15.0 requires seqeval, which is not installed.\n",
      "tf-models-official 2.15.0 requires tensorflow-datasets, which is not installed.\n",
      "tf-models-official 2.15.0 requires tensorflow-model-optimization>=0.4.1, which is not installed.\n",
      "tf-models-official 2.15.0 requires tensorflow-text~=2.15.0, which is not installed.\n",
      "tensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.13.0 which is incompatible.\n",
      "tf-models-official 2.15.0 requires tensorflow~=2.15.0, but you have tensorflow 2.13.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kiwisolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'one', 'id':1}, {'name':'five', 'id':2}, {'name':'thumbsup', 'id':3}, {'name':'thumbsdown', 'id':4}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWpb_BVUpfDD",
    "outputId": "56ce2a3f-3933-4ee6-8a9d-d5ec65f7d73c"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}\n",
    "        \n",
    "# github to converting images to file formats we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\train.record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI\\TensorflowObjectDetection\\Tensorflow\\scripts\\generate_tfrecord.py:21: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\test.record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI\\TensorflowObjectDetection\\Tensorflow\\scripts\\generate_tfrecord.py:21: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) copied.\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "uQA13-afpfDF",
    "outputId": "907496a4-a39d-4b13-8c2c-e5978ecb1f10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 4\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 4e-005\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0\n",
       "           stddev: 0.01\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.997\n",
       "         scale: true\n",
       "         epsilon: 0.001\n",
       "       }\n",
       "     }\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     use_depthwise: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10\n",
       "       x_scale: 10\n",
       "       height_scale: 5\n",
       "       width_scale: 5\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 4e-005\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0\n",
       "             stddev: 0.01\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.997\n",
       "           scale: true\n",
       "           epsilon: 0.001\n",
       "         }\n",
       "       }\n",
       "       num_layers_before_predictor: 4\n",
       "       depth: 128\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.6\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4\n",
       "       aspect_ratios: 1\n",
       "       aspect_ratios: 2\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 1e-008\n",
       "       iou_threshold: 0.6\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1\n",
       "     localization_weight: 1\n",
       "   }\n",
       "   freeze_batchnorm: false\n",
       "   inplace_batchnorm_update: true\n",
       " },\n",
       " 'train_config': batch_size: 4\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3\n",
       "     min_area: 0.75\n",
       "     max_area: 1\n",
       "     overlap_thresh: 0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.08\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.9\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"Tensorflow\\\\workspace\\\\pre-trained-models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\checkpoint\\\\ckpt-0\"\n",
       " fine_tune_checkpoint_type: \"detection\"\n",
       " fine_tune_checkpoint_version: V2\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false,\n",
       " 'train_input_config': label_map_path: \"Tensorflow\\\\workspace\\\\annotations\\\\label_map.pbtxt\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"Tensorflow\\\\workspace\\\\annotations\\\\train.record\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"Tensorflow\\\\workspace\\\\annotations\\\\label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"Tensorflow\\\\workspace\\\\annotations\\\\test.record\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"Tensorflow\\\\workspace\\\\annotations\\\\label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"Tensorflow\\\\workspace\\\\annotations\\\\test.record\"\n",
       " }}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=3000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\pipeline.config --num_train_steps=3000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225"
   },
   "outputs": [],
   "source": [
    "!{command}\n",
    "# run the command (output from print(command) from the upper cell) from cmd to monitor the training MAKE SURE TO RUN IN AFTER ACTIVATING THE VIRTUAL ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\pipeline.config --checkpoint_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqTV2jGBpfDH"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# 9. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y_MKiuZ4pfDI"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Lx3crOhOzITB"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'thumbsdown.c5525fff-c5bd-11ee-8da4-a8a159458426.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3"
   },
   "outputs": [],
   "source": [
    "# detect objects using image\n",
    "\n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsNAaYAo0WVL"
   },
   "source": [
    "# 10. Real Time Detections from your Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python-headless -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "o_grs6OGpfDJ"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzlM4jt0pfDJ"
   },
   "source": [
    "# 10. Freezing the Graph (save the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "n4olHB2npfDJ"
   },
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0AjO93QDpfDJ"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Lsp3tCpfDJ",
    "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow\\models\\research\\object_detection\\exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\pipeline.config --trained_checkpoint_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned --output_directory=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\export\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "1Sw1ULgHpfDJ",
    "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\AI\\TensorflowObjectDetection\\tfod\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0209 22:04:09.778461  7768 deprecation.py:641] From D:\\AI\\TensorflowObjectDetection\\tfod\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "I0209 22:04:12.763463  7768 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "I0209 22:04:19.583463  7768 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "I0209 22:04:21.870464  7768 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_predictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\n",
      "I0209 22:04:22.795461  7768 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001687FDC6A40>, because it is not built.\n",
      "W0209 22:04:24.683465  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001687FDC6A40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000168012C3D30>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000168012C3D30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025FF580>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025FF580>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025FCAC0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025FCAC0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000168025FC880>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000168025FC880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025FF6A0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025FF6A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025FD180>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025FD180>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000168025FCAF0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000168025FCAF0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025FC4F0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025FC4F0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016801003BE0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016801003BE0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x0000016801002B30>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x0000016801002B30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016801003DC0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016801003DC0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016801001CF0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016801001CF0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168014494E0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168014494E0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802590070>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802590070>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025920E0>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025920E0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802592D70>, because it is not built.\n",
      "W0209 22:04:24.886461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802592D70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802591E10>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802591E10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802593AF0>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802593AF0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802593A30>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802593A30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802591870>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802591870>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802551300>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802551300>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802550910>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802550910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802553940>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802553940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802550C40>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802550C40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025536D0>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025536D0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802550790>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802550790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802553490>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000016802553490>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802551780>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000016802551780>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168024EB6A0>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168024EB6A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168024E9F30>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168024E9F30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168024EBDC0>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168024EBDC0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168011E4670>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168011E4670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168011E4DC0>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168011E4DC0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168011E5960>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168011E5960>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168011E78E0>, because it is not built.\n",
      "W0209 22:04:24.887461  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168011E78E0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168011E7A30>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168011E7A30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168011E6020>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168011E6020>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025A7CA0>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025A7CA0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025A6BC0>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025A6BC0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025A5F00>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025A5F00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025A5240>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025A5240>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025A5930>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025A5930>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025A6350>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000168025A6350>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025A4640>, because it is not built.\n",
      "W0209 22:04:24.888462  7768 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000168025A4640>, because it is not built.\n",
      "I0209 22:04:32.587463  7768 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\export\\saved_model\\assets\n",
      "I0209 22:04:36.443463  7768 builder_impl.py:804] Assets written to: Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\export\\saved_model\\assets\n",
      "I0209 22:04:36.463464  7768 fingerprinting_utils.py:48] Writing fingerprint to Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\export\\saved_model\\fingerprint.pb\n",
      "INFO:tensorflow:Writing pipeline config file to Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\export\\pipeline.config\n",
      "I0209 22:04:36.955461  7768 config_util.py:253] Writing pipeline config file to Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\export\\pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTPmdqaXpfDK"
   },
   "source": [
    "# 11. Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "gZ6UzY_fpfDK",
    "outputId": "0c84722e-1c2b-4002-d857-80827ade828a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-4.17.0-py3-none-any.whl (89 kB)\n",
      "Requirement already satisfied: six<2,>=1.16.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.14.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (0.16.1)\n",
      "Requirement already satisfied: jaxlib>=0.4.13 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (0.4.24)\n",
      "Requirement already satisfied: importlib_resources>=5.9.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (6.1.1)\n",
      "Requirement already satisfied: jax>=0.4.13 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (0.4.24)\n",
      "Requirement already satisfied: flax>=0.7.2 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (0.8.1)\n",
      "Requirement already satisfied: tensorflow<3,>=2.13.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-decision-forests>=1.5.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (1.8.1)\n",
      "Requirement already satisfied: packaging~=23.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflowjs) (23.2)\n",
      "Requirement already satisfied: rich>=11.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\rich-13.7.0-py3.10.egg (from flax>=0.7.2->tensorflowjs) (13.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from flax>=0.7.2->tensorflowjs) (4.5.0)\n",
      "Requirement already satisfied: optax in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from flax>=0.7.2->tensorflowjs) (0.1.9)\n",
      "Requirement already satisfied: msgpack in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from flax>=0.7.2->tensorflowjs) (1.0.7)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from flax>=0.7.2->tensorflowjs) (6.0.1)\n",
      "Requirement already satisfied: tensorstore in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from flax>=0.7.2->tensorflowjs) (0.1.45)\n",
      "Requirement already satisfied: numpy>=1.22 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from flax>=0.7.2->tensorflowjs) (1.24.3)\n",
      "Requirement already satisfied: orbax-checkpoint in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from flax>=0.7.2->tensorflowjs) (0.4.4)\n",
      "Requirement already satisfied: opt-einsum in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from jax>=0.4.13->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from jax>=0.4.13->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.9 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\scipy-1.12.0-py3.10-win-amd64.egg (from jax>=0.4.13->tensorflowjs) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.15.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\absl_py-2.1.0-py3.10.egg (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\tensorflow_io_gcs_filesystem-0.31.0-py3.10-win-amd64.egg (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.31.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\h5py-3.10.0-py3.10-win-amd64.egg (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.60.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (23.5.26)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (16.0.6)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
      "Requirement already satisfied: setuptools in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (65.5.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (4.23.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.4.0)\n",
      "Requirement already satisfied: wurlitzer in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (3.0.3)\n",
      "Requirement already satisfied: wheel in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.42.0)\n",
      "Requirement already satisfied: pandas in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages\\pandas-2.2.0-py3.10-win-amd64.egg (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.0)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorflow-hub>=0.14.0->tensorflowjs) (2.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.17.2)\n",
      "Requirement already satisfied: chex>=0.1.7 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.85)\n",
      "Requirement already satisfied: etils[epath,epy] in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
      "Requirement already satisfied: nest_asyncio in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2023.4)\n",
      "Requirement already satisfied: toolz>=0.9.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from chex>=0.1.7->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.31.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.5.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.1)\n",
      "Requirement already satisfied: fsspec in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2024.2.0)\n",
      "Requirement already satisfied: zipp in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.17.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.2.2)\n",
      "Installing collected packages: tensorflowjs\n",
      "Successfully installed tensorflowjs-4.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\ai\\tensorflowobjectdetection\\tfod\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0oxbVynHpfDK"
   },
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2AGNmJpfDK",
    "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\\saved_model Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfjsexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7rfT4-hpfDK",
    "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow Decision Forests.\n",
    "!pip3 install tensorflow_decision_forests --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8_hm-itpfDK"
   },
   "outputs": [],
   "source": [
    "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 12. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow\\models\\research\\object_detection\\export_tflite_graph_tf2.py  --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\pipeline.config --trained_checkpoint_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned --output_directory=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\tfliteexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0209 22:05:01.805520  5748 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "I0209 22:05:05.207515  5748 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "I0209 22:05:06.098516  5748 signature_serialization.py:148] Function `inference_fn` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_predictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\n",
      "I0209 22:05:06.910515  5748 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000002694FF95450>, because it is not built.\n",
      "W0209 22:05:07.758516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000002694FF95450>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000269501D1DB0>, because it is not built.\n",
      "W0209 22:05:07.979516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000269501D1DB0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695174DB70>, because it is not built.\n",
      "W0209 22:05:07.979516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695174DB70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026950109A80>, because it is not built.\n",
      "W0209 22:05:07.979516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026950109A80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000269502477F0>, because it is not built.\n",
      "W0209 22:05:07.979516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000269502477F0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000269502443A0>, because it is not built.\n",
      "W0209 22:05:07.979516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000269502443A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026950244DC0>, because it is not built.\n",
      "W0209 22:05:07.979516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026950244DC0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x0000026950247EB0>, because it is not built.\n",
      "W0209 22:05:07.979516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x0000026950247EB0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026950246290>, because it is not built.\n",
      "W0209 22:05:07.979516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026950246290>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951543910>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951543910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000269515428C0>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x00000269515428C0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951543610>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951543610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951540910>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951540910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951542800>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951542800>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951543970>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951543970>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695025B4F0>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695025B4F0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000269500F7730>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000269500F7730>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000269500F46D0>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000269500F46D0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000269500F55A0>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000269500F55A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000269500F7B20>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000269500F7B20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000269500F7B50>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x00000269500F7B50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951B4AAA0>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951B4AAA0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951B48670>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951B48670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951B48B80>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951B48B80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951B49B70>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951B49B70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951B48400>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951B48400>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951B486A0>, because it is not built.\n",
      "W0209 22:05:07.980516  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951B486A0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951B4AA70>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951B4AA70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951B4A800>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951B4A800>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026950146050>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026950146050>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951828820>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951828820>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695182BD60>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695182BD60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695182A860>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695182A860>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000269518281F0>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000269518281F0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695182B490>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695182B490>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695182A680>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695182A680>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951829660>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951829660>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951466E30>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951466E30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695157BEE0>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695157BEE0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951578D60>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000026951578D60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951579330>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x0000026951579330>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695157AB30>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695157AB30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695157B280>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695157B280>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695157BAF0>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x000002695157BAF0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695157B670>, because it is not built.\n",
      "W0209 22:05:07.981515  5748 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x000002695157B670>, because it is not built.\n",
      "I0209 22:05:15.732516  5748 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\tfliteexport\\saved_model\\assets\n",
      "I0209 22:05:19.534516  5748 builder_impl.py:804] Assets written to: Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\tfliteexport\\saved_model\\assets\n",
      "I0209 22:05:19.553517  5748 fingerprinting_utils.py:48] Writing fingerprint to Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\tfliteexport\\saved_model\\fingerprint.pb\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflite_convert --saved_model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\tfliteexport\\saved_model --output_file=Tensorflow\\workspace\\models\\my_ssd_mobnet_tuned\\tfliteexport\\saved_model\\detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 22:06:01.077807: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-02-09 22:06:01.077873: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NQqZRdA21Uc"
   },
   "source": [
    "# 13. Zip and Export Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTVTGCQp2ZJJ"
   },
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whShhB0x3PYJ",
    "outputId": "b773201d-35c9-46a8-b893-4a76bd4d5d97"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
